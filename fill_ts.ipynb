{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = pyspark.SparkContext(appName='Python Spark SQL basic example')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.parallelize(Seq[999-999, 100.00, 10-10-2014;])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank_dates(self, df, today_date, days):\n",
    "        '''\n",
    "        This function is create to add to dates that has no saldo, adding the old saldo\n",
    "\n",
    "            >>> df.show()\n",
    "            +---------------+-------------+-------------+\n",
    "            |next_account_id|        saldo|         data|\n",
    "            +---------------+-------------+-------------+\n",
    "            |        999-999|       100.00|   10-10-2014|\n",
    "            |        999-999|       150.00|   15-10-2014|\n",
    "            +---------------+-------------+-------------+\n",
    "            >>> fill_blank_dates(df, end_date, 5).show()\n",
    "            +---------------+-------------+-------------+\n",
    "            |next_account_id|        saldo|         data|\n",
    "            +---------------+-------------+-------------+\n",
    "            |        999-999|       100.00|   10-10-2014|\n",
    "            |        999-999|       100.00|   11-10-2014|\n",
    "            |        999-999|       100.00|   12-10-2014|\n",
    "            |        999-999|       100.00|   13-10-2014|\n",
    "            |        999-999|       100.00|   14-10-2014|\n",
    "            |        999-999|       150.00|   15-10-2014|\n",
    "            +---------------+-------------+-------------+\n",
    "        :param df: dataframe with columns ['next_account_id', 'saldo', 'data']\n",
    "        :param today_date: data of today\n",
    "        :param days: how many days away\n",
    "        :return: dataframe with columns ['next_account_id', 'saldo', 'data']\n",
    "        '''\n",
    "        data_to_append = [['99999_99999', -1, (today_date - timedelta(days=x)).strftime('%Y-%m-%d')] for x in\n",
    "                          range(0, days)]\n",
    "        df_to_append = self.sc.parallelize(data_to_append).toDF(['next_account_id', 'saldo', 'data'])\n",
    "        new_df = df.unionAll(df_to_append)\n",
    "        pivot_table = new_df.groupBy('next_account_id')\\\n",
    "                            .pivot('data')\\\n",
    "                            .max('saldo')\\\n",
    "                            .na.fill(0)\n",
    "        columns_list = [x.name for x in pivot_table.schema.fields]\n",
    "        temporal_data = pivot_table.rdd \\\n",
    "                                   .map(lambda row: create_temporal(row, columns_list)) \\\n",
    "                                   .flatMapValues(lambda x: x) \\\n",
    "                                   .map(lambda row: (row[0], row[1][0], row[1][1])) \\\n",
    "                                   .toDF(['next_account_id', 'data', 'saldo'])\n",
    "        return temporal_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
